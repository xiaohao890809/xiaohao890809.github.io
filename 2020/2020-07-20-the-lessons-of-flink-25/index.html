<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta http-equiv="content-type" content="text/html;charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="robots" content="noodp"/>
  <meta name="author" content="追寻原风景">
  
  
  
  <link rel="prev" href="https://xiaohao890809.github.io/2020/2020-07-20-the-lessons-of-flink-24/" />
  <link rel="next" href="https://xiaohao890809.github.io/2020/2020-07-20-the-lessons-of-flink-26/" />
  <link rel="canonical" href="https://xiaohao890809.github.io/2020/2020-07-20-the-lessons-of-flink-25/" />
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  <title>
       
       
           第24讲：Flink 消费 Kafka 数据业务开发 | 枕霞惜友
       
  </title>
  <meta name="title" content="第24讲：Flink 消费 Kafka 数据业务开发 | 枕霞惜友">
    
  
  <link rel="stylesheet" href="/font/iconfont.css">
  <link rel="stylesheet" href="/css/main.min.css">


  
  
 

<script type="application/ld+json">
{
    "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "https:\/\/xiaohao890809.github.io"
    },
    "articleSection" : "posts",
    "name" : "第24讲：Flink 消费 Kafka 数据业务开发",
    "headline" : "第24讲：Flink 消费 Kafka 数据业务开发",
    "description" : "在上一课时中我们提过在实时计算的场景下，绝大多数的数据源都是消息系统，而 Kafka 从众多的消息中间件中脱颖而出，主要是因为高吞吐、低延迟的特点；同时也讲了 Flink 作为生产者像 Kafka 写入数据的方式和代码实现。这一课时我们将从以下几个方面介绍 Flink 消费 Kafka 中的数据方式和源码实现。\nFlink 如何消费 Kafka Flink 在和 Kafka 对接的过程中，跟 Kafka 的版本是强相关的。上一课时也提到了，我们在使用 Kafka 连接器时需要引用相对应的 Jar 包依赖，对于某些连接器比如 Kafka 是有版本要求的，一定要去官方网站找到对应的依赖版本。\n我们本地的 Kafka 版本是 2.1.0，所以需要对应的类是 FlinkKafkaConsumer。首先需要在 pom.xml 中引入 jar 包依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.flink\u0026lt;\/groupId\u0026gt; \u0026lt;artifactId\u0026gt;flink-connector-kafka_2.11\u0026lt;\/artifactId\u0026gt; \u0026lt;version\u0026gt;1.10.0\u0026lt;\/version\u0026gt; \u0026lt;\/dependency\u0026gt; 下面将对 Flink 消费 Kafka 数据的方式进行分类讲解。\n消费单个 Topic 上一课时我们在本地搭建了 Kafka 环境，并且手动创建了名为 test 的 Topic，然后向名为 test 的 Topic 中写入了数据。\n那么现在我们要消费这个 Topic 中的数据，该怎么做呢？\npublic static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.",
    "inLanguage" : "en-us",
    "author" : "王知无",
    "creator" : "王知无",
    "publisher": "王知无",
    "accountablePerson" : "王知无",
    "copyrightHolder" : "王知无",
    "copyrightYear" : "2020",
    "datePublished": "2020-07-20 10:36:48 \u002b0000 UTC",
    "dateModified" : "2020-07-20 10:36:48 \u002b0000 UTC",
    "url" : "https:\/\/xiaohao890809.github.io\/2020\/2020-07-20-the-lessons-of-flink-25\/",
    "wordCount" : "1065",
    "keywords" : [ "42讲轻松通关Flink", "枕霞惜友"]
}
</script>

</head>

  


  <body class="">
    <div class="wrapper">
        <nav class="navbar">
    
        <div class="top-scroll-bar"></div>
    
    <div class="container">
        <div class="navbar-header header-logo">
        	<a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://xiaohao890809.github.io">枕霞惜友</a>
        </div>
        <div class="menu navbar-right">
                
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
        </div>
    </div>
</nav>
<nav class="navbar-mobile" id="nav-mobile" style="display: none">
    
        <div class="top-scroll-bar"></div>
    
     <div class="container">
        <div class="navbar-header">
            <div>  <a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://xiaohao890809.github.io">枕霞惜友</a></div>
            <div class="menu-toggle">
                <span></span><span></span><span></span>
            </div>
        </div>
     
          <div class="menu" id="mobile-menu">
                
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
        </div>
    </div>
</nav>
    	 <main class="main">
          <div class="container">
      		
<article class="post-warp" itemscope itemtype="http://schema.org/Article">
    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">第24讲：Flink 消费 Kafka 数据业务开发</h1>
        <div class="post-meta">
                Written by <a itemprop="name" href="https://xiaohao890809.github.io" rel="author">王知无</a> with ♥ 
                <span class="post-time">
                on <time datetime=2020-07-20 itemprop="datePublished">July 20, 2020</time>
                </span>
                
        </div>
    </header>

    
          <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title"></h2>
  
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#flink-如何消费-kafka">Flink 如何消费 Kafka</a>
      <ul>
        <li><a href="#消费单个-topic">消费单个 Topic</a></li>
        <li><a href="#消费多个-topic">消费多个 Topic</a></li>
        <li><a href="#消息序列化">消息序列化</a></li>
      </ul>
    </li>
    <li><a href="#parition-和-topic-动态发现">Parition 和 Topic 动态发现</a></li>
    <li><a href="#flink-消费-kafka-设置-offset-的方法">Flink 消费 Kafka 设置 offset 的方法</a></li>
    <li><a href="#flink-消费-kafka-数据代码">Flink 消费 Kafka 数据代码</a></li>
    <li><a href="#总结">总结</a></li>
  </ul>
</nav>
  </div>
</div>
<script type="text/javascript">
  window.onload = function () {
    var fix = $('.post-toc');
    var end = $('.post-comment');
    var fixTop = fix.offset().top, fixHeight = fix.height();
    var endTop, miss;
    var offsetTop = fix[0].offsetTop;
    $(window).scroll(function () {
      var docTop = Math.max(document.body.scrollTop, document.documentElement.scrollTop);
      if (end.length > 0) {
        endTop = end.offset().top;
        miss = endTop - docTop - fixHeight;
      }
      if (fixTop < docTop) {
        fix.css({ 'position': 'fixed' });
        if ((end.length > 0) && (endTop < (docTop + fixHeight))) {
          fix.css({ top: miss });
        } else {
          fix.css({ top: 0 });
        }
      } else {
        fix.css({ 'position': 'absolute' });
        fix.css({ top: offsetTop });
      }
    })
  }
</script> 
    

    <script type="text/javascript">
            window.MathJax = {
            tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
            TeX: {equationNumbers: {autoNumber: "AMS"}},
            showProcessingMessages: false,
            messageStyle: 'none'
        };
   </script>

    <script type="text/javascript" async src="/lib/mathjax/MathJax.js?config=TeX-MML-AM_CHTML"></script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"  integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>

    <div class="post-content">
        

        
            
        

        
        
     
          
          
          

          
          
          

          <p>在上一课时中我们提过在实时计算的场景下，绝大多数的数据源都是消息系统，而 Kafka 从众多的消息中间件中脱颖而出，主要是因为<strong>高吞吐、低延迟</strong>的特点；同时也讲了 Flink 作为生产者像 Kafka 写入数据的方式和代码实现。这一课时我们将从以下几个方面介绍 Flink 消费 Kafka 中的数据方式和源码实现。</p>
<h2 id="flink-如何消费-kafka">Flink 如何消费 Kafka</h2>
<p>Flink 在和 Kafka 对接的过程中，跟 Kafka 的版本是强相关的。上一课时也提到了，我们在使用 Kafka 连接器时需要引用相对应的 Jar 包依赖，对于某些连接器比如 Kafka 是有版本要求的，一定要去官方网站找到对应的依赖版本。</p>
<p>我们本地的 Kafka 版本是 2.1.0，所以需要对应的类是 FlinkKafkaConsumer。首先需要在 pom.xml 中引入 jar 包依赖：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java"><span style="color:#f92672">&lt;</span>dependency<span style="color:#f92672">&gt;</span>
  <span style="color:#f92672">&lt;</span>groupId<span style="color:#f92672">&gt;</span>org<span style="color:#f92672">.</span><span style="color:#a6e22e">apache</span><span style="color:#f92672">.</span><span style="color:#a6e22e">flink</span><span style="color:#f92672">&lt;/</span>groupId<span style="color:#f92672">&gt;</span>
  <span style="color:#f92672">&lt;</span>artifactId<span style="color:#f92672">&gt;</span>flink<span style="color:#f92672">-</span>connector<span style="color:#f92672">-</span>kafka_2<span style="color:#f92672">.</span><span style="color:#a6e22e">11</span><span style="color:#f92672">&lt;/</span>artifactId<span style="color:#f92672">&gt;</span>
  <span style="color:#f92672">&lt;</span>version<span style="color:#f92672">&gt;</span>1<span style="color:#f92672">.</span><span style="color:#a6e22e">10</span><span style="color:#f92672">.</span><span style="color:#a6e22e">0</span><span style="color:#f92672">&lt;/</span>version<span style="color:#f92672">&gt;</span>
<span style="color:#f92672">&lt;/</span>dependency<span style="color:#f92672">&gt;</span>
</code></pre></div><p>下面将对 Flink 消费 Kafka 数据的方式进行分类讲解。</p>
<h3 id="消费单个-topic">消费单个 Topic</h3>
<p>上一课时我们在本地搭建了 Kafka 环境，并且手动创建了名为 test 的 Topic，然后向名为 test 的 Topic 中写入了数据。</p>
<p>那么现在我们要消费这个 Topic 中的数据，该怎么做呢？</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java"><span style="color:#66d9ef">public</span> <span style="color:#66d9ef">static</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">main</span><span style="color:#f92672">(</span>String<span style="color:#f92672">[]</span> args<span style="color:#f92672">)</span> <span style="color:#66d9ef">throws</span> Exception <span style="color:#f92672">{</span>
    StreamExecutionEnvironment env <span style="color:#f92672">=</span> StreamExecutionEnvironment<span style="color:#f92672">.</span><span style="color:#a6e22e">getExecutionEnvironment</span><span style="color:#f92672">();</span>
    env<span style="color:#f92672">.</span><span style="color:#a6e22e">getCheckpointConfig</span><span style="color:#f92672">().</span><span style="color:#a6e22e">setCheckpointingMode</span><span style="color:#f92672">(</span>CheckpointingMode<span style="color:#f92672">.</span><span style="color:#a6e22e">EXACTLY_ONCE</span><span style="color:#f92672">);</span>
    env<span style="color:#f92672">.</span><span style="color:#a6e22e">enableCheckpointing</span><span style="color:#f92672">(</span>5000<span style="color:#f92672">);</span>
    Properties properties <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> Properties<span style="color:#f92672">();</span>
    properties<span style="color:#f92672">.</span><span style="color:#a6e22e">setProperty</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;bootstrap.servers&#34;</span><span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;127.0.0.1:9092&#34;</span><span style="color:#f92672">);</span>
    <span style="color:#75715e">// 如果你是0.8版本的Kafka，需要配置
</span><span style="color:#75715e"></span>    <span style="color:#75715e">//properties.setProperty(&#34;zookeeper.connect&#34;, &#34;localhost:2181&#34;);
</span><span style="color:#75715e"></span>    <span style="color:#75715e">//设置消费组
</span><span style="color:#75715e"></span>    properties<span style="color:#f92672">.</span><span style="color:#a6e22e">setProperty</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;group.id&#34;</span><span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;group_test&#34;</span><span style="color:#f92672">);</span>
    FlinkKafkaConsumer<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">&gt;</span> consumer <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> FlinkKafkaConsumer<span style="color:#f92672">&lt;&gt;(</span><span style="color:#e6db74">&#34;test&#34;</span><span style="color:#f92672">,</span> <span style="color:#66d9ef">new</span> SimpleStringSchema<span style="color:#f92672">(),</span> properties<span style="color:#f92672">);</span>
    <span style="color:#75715e">//设置从最早的ffset消费
</span><span style="color:#75715e"></span>    consumer<span style="color:#f92672">.</span><span style="color:#a6e22e">setStartFromEarliest</span><span style="color:#f92672">();</span>
    <span style="color:#75715e">//还可以手动指定相应的 topic, partition，offset,然后从指定好的位置开始消费
</span><span style="color:#75715e"></span>    <span style="color:#75715e">//HashMap&lt;KafkaTopicPartition, Long&gt; map = new HashMap&lt;&gt;();
</span><span style="color:#75715e"></span>    <span style="color:#75715e">//map.put(new KafkaTopicPartition(&#34;test&#34;, 1), 10240L);
</span><span style="color:#75715e"></span>    <span style="color:#75715e">//假如partition有多个，可以指定每个partition的消费位置
</span><span style="color:#75715e"></span>    <span style="color:#75715e">//map.put(new KafkaTopicPartition(&#34;test&#34;, 2), 10560L);
</span><span style="color:#75715e"></span>    <span style="color:#75715e">//然后各个partition从指定位置消费
</span><span style="color:#75715e"></span>    <span style="color:#75715e">//consumer.setStartFromSpecificOffsets(map);
</span><span style="color:#75715e"></span>    env<span style="color:#f92672">.</span><span style="color:#a6e22e">addSource</span><span style="color:#f92672">(</span>consumer<span style="color:#f92672">).</span><span style="color:#a6e22e">flatMap</span><span style="color:#f92672">(</span><span style="color:#66d9ef">new</span> FlatMapFunction<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">,</span> String<span style="color:#f92672">&gt;()</span> <span style="color:#f92672">{</span>
        <span style="color:#a6e22e">@Override</span>
        <span style="color:#66d9ef">public</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">flatMap</span><span style="color:#f92672">(</span>String value<span style="color:#f92672">,</span> Collector<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">&gt;</span> out<span style="color:#f92672">)</span> <span style="color:#66d9ef">throws</span> Exception <span style="color:#f92672">{</span>
            System<span style="color:#f92672">.</span><span style="color:#a6e22e">out</span><span style="color:#f92672">.</span><span style="color:#a6e22e">println</span><span style="color:#f92672">(</span>value<span style="color:#f92672">);</span>
        <span style="color:#f92672">}</span>
    <span style="color:#f92672">});</span>
    env<span style="color:#f92672">.</span><span style="color:#a6e22e">execute</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;start consumer...&#34;</span><span style="color:#f92672">);</span>
<span style="color:#f92672">}</span>
</code></pre></div><p>在设置消费 Kafka 中的数据时，可以显示地指定从某个 Topic 的每一个 Partition 中进行消费。</p>
<h3 id="消费多个-topic">消费多个 Topic</h3>
<p>我们的业务中会有这样的情况，同样的数据根据类型不同发送到了不同的 Topic 中，比如线上的订单数据根据来源不同分别发往移动端和 PC 端两个 Topic 中。但是我们不想把同样的代码复制一份，需重新指定一个 Topic 进行消费，这时候应该怎么办呢？</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java">Properties properties <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> Properties<span style="color:#f92672">();</span>
properties<span style="color:#f92672">.</span><span style="color:#a6e22e">setProperty</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;bootstrap.servers&#34;</span><span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;127.0.0.1:9092&#34;</span><span style="color:#f92672">);</span>
<span style="color:#75715e">// 如果你是0.8版本的Kafka，需要配置
</span><span style="color:#75715e">//properties.setProperty(&#34;zookeeper.connect&#34;, &#34;localhost:2181&#34;);
</span><span style="color:#75715e">//设置消费组
</span><span style="color:#75715e"></span>properties<span style="color:#f92672">.</span><span style="color:#a6e22e">setProperty</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;group.id&#34;</span><span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;group_test&#34;</span><span style="color:#f92672">);</span>
FlinkKafkaConsumer<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">&gt;</span> consumer <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> FlinkKafkaConsumer<span style="color:#f92672">&lt;&gt;(</span><span style="color:#e6db74">&#34;test&#34;</span><span style="color:#f92672">,</span> <span style="color:#66d9ef">new</span> SimpleStringSchema<span style="color:#f92672">(),</span> properties<span style="color:#f92672">);</span>
ArrayList<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">&gt;</span> topics <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> ArrayList<span style="color:#f92672">&lt;&gt;();</span>
        topics<span style="color:#f92672">.</span><span style="color:#a6e22e">add</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;test_A&#34;</span><span style="color:#f92672">);</span>
        topics<span style="color:#f92672">.</span><span style="color:#a6e22e">add</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;test_B&#34;</span><span style="color:#f92672">);</span>
       <span style="color:#75715e">// 传入一个 list，完美解决了这个问题
</span><span style="color:#75715e"></span>        FlinkKafkaConsumer<span style="color:#f92672">&lt;</span>Tuple2<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">,</span> String<span style="color:#f92672">&gt;&gt;</span> consumer <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> FlinkKafkaConsumer<span style="color:#f92672">&lt;&gt;(</span>topics<span style="color:#f92672">,</span> <span style="color:#66d9ef">new</span> SimpleStringSchema<span style="color:#f92672">(),</span> properties<span style="color:#f92672">);</span>
<span style="color:#f92672">...</span>
</code></pre></div><p>我们可以传入一个 list 来解决消费多个 Topic 的问题，如果用户需要区分两个 Topic 中的数据，那么需要在发往 Kafka 中数据新增一个字段，用来区分来源。</p>
<h3 id="消息序列化">消息序列化</h3>
<p>我们在上述消费 Kafka 消息时，都默认指定了消息的序列化方式，即 SimpleStringSchema。这里需要注意的是，在我们使用 SimpleStringSchema 的时候，返回的结果中只有原数据，没有 topic、parition 等信息，这时候可以自定义序列化的方式来实现自定义返回数据的结构。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java"><span style="color:#66d9ef">public</span> <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CustomDeSerializationSchema</span> <span style="color:#66d9ef">implements</span> KafkaDeserializationSchema<span style="color:#f92672">&lt;</span>ConsumerRecord<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">,</span> String<span style="color:#f92672">&gt;&gt;</span> <span style="color:#f92672">{</span>
    <span style="color:#75715e">//是否表示流的最后一条元素,设置为false，表示数据会源源不断地到来
</span><span style="color:#75715e"></span>    <span style="color:#a6e22e">@Override</span>
    <span style="color:#66d9ef">public</span> <span style="color:#66d9ef">boolean</span> <span style="color:#a6e22e">isEndOfStream</span><span style="color:#f92672">(</span>ConsumerRecord<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">,</span> String<span style="color:#f92672">&gt;</span> nextElement<span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
        <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">false</span><span style="color:#f92672">;</span>
    <span style="color:#f92672">}</span>
    <span style="color:#75715e">//这里返回一个ConsumerRecord&lt;String,String&gt;类型的数据，除了原数据还包括topic，offset，partition等信息
</span><span style="color:#75715e"></span>    <span style="color:#a6e22e">@Override</span>
    <span style="color:#66d9ef">public</span> ConsumerRecord<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">,</span> String<span style="color:#f92672">&gt;</span> <span style="color:#a6e22e">deserialize</span><span style="color:#f92672">(</span>ConsumerRecord<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">byte</span><span style="color:#f92672">[],</span> <span style="color:#66d9ef">byte</span><span style="color:#f92672">[]&gt;</span> record<span style="color:#f92672">)</span> <span style="color:#66d9ef">throws</span> Exception <span style="color:#f92672">{</span>
        <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">new</span> ConsumerRecord<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">,</span> String<span style="color:#f92672">&gt;(</span>
                record<span style="color:#f92672">.</span><span style="color:#a6e22e">topic</span><span style="color:#f92672">(),</span>
                record<span style="color:#f92672">.</span><span style="color:#a6e22e">partition</span><span style="color:#f92672">(),</span>
                record<span style="color:#f92672">.</span><span style="color:#a6e22e">offset</span><span style="color:#f92672">(),</span>
                <span style="color:#66d9ef">new</span> String<span style="color:#f92672">(</span>record<span style="color:#f92672">.</span><span style="color:#a6e22e">key</span><span style="color:#f92672">()),</span>
                <span style="color:#66d9ef">new</span> String<span style="color:#f92672">(</span>record<span style="color:#f92672">.</span><span style="color:#a6e22e">value</span><span style="color:#f92672">())</span>
        <span style="color:#f92672">);</span>
    <span style="color:#f92672">}</span>
    <span style="color:#75715e">//指定数据的输入类型
</span><span style="color:#75715e"></span>    <span style="color:#a6e22e">@Override</span>
    <span style="color:#66d9ef">public</span> TypeInformation<span style="color:#f92672">&lt;</span>ConsumerRecord<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">,</span> String<span style="color:#f92672">&gt;&gt;</span> <span style="color:#a6e22e">getProducedType</span><span style="color:#f92672">()</span> <span style="color:#f92672">{</span>
        <span style="color:#66d9ef">return</span> TypeInformation<span style="color:#f92672">.</span><span style="color:#a6e22e">of</span><span style="color:#f92672">(</span><span style="color:#66d9ef">new</span> TypeHint<span style="color:#f92672">&lt;</span>ConsumerRecord<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">,</span> String<span style="color:#f92672">&gt;&gt;(){});</span>
    <span style="color:#f92672">}</span>
<span style="color:#f92672">}</span>
</code></pre></div><p>这里自定义了 CustomDeSerializationSchema 信息，就可以直接使用了。</p>
<h2 id="parition-和-topic-动态发现">Parition 和 Topic 动态发现</h2>
<p>在很多场景下，随着业务的扩展，我们需要对 Kafka 的分区进行扩展，为了防止新增的分区没有被及时发现导致数据丢失，消费者必须要感知 Partition 的动态变化，可以使用 FlinkKafkaConsumer 的动态分区发现实现。</p>
<p>我们只需要指定下面的配置，即可打开动态分区发现功能：每隔 10ms 会动态获取 Topic 的元数据，对于新增的 Partition 会自动从最早的位点开始消费数据。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java">properties<span style="color:#f92672">.</span><span style="color:#a6e22e">setProperty</span><span style="color:#f92672">(</span>FlinkKafkaConsumerBase<span style="color:#f92672">.</span><span style="color:#a6e22e">KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS</span><span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;10&#34;</span><span style="color:#f92672">);</span>
</code></pre></div><p>如果业务场景需要我们动态地发现 Topic，可以指定 Topic 的正则表达式：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java">FlinkKafkaConsumer<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">&gt;</span> consumer <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> FlinkKafkaConsumer<span style="color:#f92672">&lt;&gt;(</span>Pattern<span style="color:#f92672">.</span><span style="color:#a6e22e">compile</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;^test_([A-Za-z0-9]*)$&#34;</span><span style="color:#f92672">),</span> <span style="color:#66d9ef">new</span> SimpleStringSchema<span style="color:#f92672">(),</span> properties<span style="color:#f92672">);</span>
</code></pre></div><h2 id="flink-消费-kafka-设置-offset-的方法">Flink 消费 Kafka 设置 offset 的方法</h2>
<p>Flink 消费 Kafka 需要指定消费的 offset，也就是偏移量。Flink 读取 Kafka 的消息有五种消费方式：</p>
<ul>
<li>指定 Topic 和 Partition</li>
<li>从最早位点开始消费</li>
<li>从指定时间点开始消费</li>
<li>从最新的数据开始消费</li>
<li>从上次消费位点开始消费</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java"><span style="color:#75715e">/**
</span><span style="color:#75715e">* Flink从指定的topic和parition中指定的offset开始
</span><span style="color:#75715e">*/</span>
Map<span style="color:#f92672">&lt;</span>KafkaTopicPartition<span style="color:#f92672">,</span> Long<span style="color:#f92672">&gt;</span> offsets <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> HashedMap<span style="color:#f92672">();</span>
offsets<span style="color:#f92672">.</span><span style="color:#a6e22e">put</span><span style="color:#f92672">(</span><span style="color:#66d9ef">new</span> KafkaTopicPartition<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;test&#34;</span><span style="color:#f92672">,</span> 0<span style="color:#f92672">),</span> 10000L<span style="color:#f92672">);</span>
offsets<span style="color:#f92672">.</span><span style="color:#a6e22e">put</span><span style="color:#f92672">(</span><span style="color:#66d9ef">new</span> KafkaTopicPartition<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;test&#34;</span><span style="color:#f92672">,</span> 1<span style="color:#f92672">),</span> 20000L<span style="color:#f92672">);</span>
offsets<span style="color:#f92672">.</span><span style="color:#a6e22e">put</span><span style="color:#f92672">(</span><span style="color:#66d9ef">new</span> KafkaTopicPartition<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;test&#34;</span><span style="color:#f92672">,</span> 2<span style="color:#f92672">),</span> 30000L<span style="color:#f92672">);</span>
consumer<span style="color:#f92672">.</span><span style="color:#a6e22e">setStartFromSpecificOffsets</span><span style="color:#f92672">(</span>offsets<span style="color:#f92672">);</span>
<span style="color:#75715e">/**
</span><span style="color:#75715e">* Flink从topic中最早的offset消费
</span><span style="color:#75715e">*/</span>
consumer<span style="color:#f92672">.</span><span style="color:#a6e22e">setStartFromEarliest</span><span style="color:#f92672">();</span>
<span style="color:#75715e">/**
</span><span style="color:#75715e">* Flink从topic中指定的时间点开始消费
</span><span style="color:#75715e">*/</span>
consumer<span style="color:#f92672">.</span><span style="color:#a6e22e">setStartFromTimestamp</span><span style="color:#f92672">(</span>1559801580000l<span style="color:#f92672">);</span>
<span style="color:#75715e">/**
</span><span style="color:#75715e">* Flink从topic中最新的数据开始消费
</span><span style="color:#75715e">*/</span>
consumer<span style="color:#f92672">.</span><span style="color:#a6e22e">setStartFromLatest</span><span style="color:#f92672">();</span>
<span style="color:#75715e">/**
</span><span style="color:#75715e">* Flink从topic中指定的group上次消费的位置开始消费，所以必须配置group.id参数
</span><span style="color:#75715e">*/</span>
consumer<span style="color:#f92672">.</span><span style="color:#a6e22e">setStartFromGroupOffsets</span><span style="color:#f92672">();</span>
</code></pre></div><p>源码解析</p>
<p><figure><img src="/images/ring.svg" data-src="/images/FlinkKafkaConsumer.png" data-sizes="auto" alt="FlinkKafkaConsumer" title="FlinkKafkaConsumer" class="lazyload"><figcaption class="image-caption">FlinkKafkaConsumer</figcaption></figure></p>
<p>从上面的类图可以看出，FlinkKafkaConsumer 继承了 FlinkKafkaConsumerBase，而 FlinkKafkaConsumerBase 最终是对 SourceFunction 进行了实现。</p>
<p>整体的流程：FlinkKafkaConsumer 首先创建了 KafkaFetcher 对象，然后 KafkaFetcher 创建了 KafkaConsumerThread 和 Handover，KafkaConsumerThread 负责直接从 Kafka 中读取 msg，并交给 Handover，然后 Handover 将 msg 传递给 KafkaFetcher.emitRecord 将消息发出。</p>
<p>因为 FlinkKafkaConsumerBase 实现了 RichFunction 接口，所以当程序启动的时候，会首先调用 FlinkKafkaConsumerBase.open 方法：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java"><span style="color:#66d9ef">public</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">open</span><span style="color:#f92672">(</span>Configuration configuration<span style="color:#f92672">)</span> <span style="color:#66d9ef">throws</span> Exception <span style="color:#f92672">{</span>
   <span style="color:#75715e">// 指定offset的提交方式
</span><span style="color:#75715e"></span>   <span style="color:#66d9ef">this</span><span style="color:#f92672">.</span><span style="color:#a6e22e">offsetCommitMode</span> <span style="color:#f92672">=</span> OffsetCommitModes<span style="color:#f92672">.</span><span style="color:#a6e22e">fromConfiguration</span><span style="color:#f92672">(</span>
         getIsAutoCommitEnabled<span style="color:#f92672">(),</span>
         enableCommitOnCheckpoints<span style="color:#f92672">,</span>
         <span style="color:#f92672">((</span>StreamingRuntimeContext<span style="color:#f92672">)</span> getRuntimeContext<span style="color:#f92672">()).</span><span style="color:#a6e22e">isCheckpointingEnabled</span><span style="color:#f92672">());</span>
   <span style="color:#75715e">// 创建分区发现器
</span><span style="color:#75715e"></span>   <span style="color:#66d9ef">this</span><span style="color:#f92672">.</span><span style="color:#a6e22e">partitionDiscoverer</span> <span style="color:#f92672">=</span> createPartitionDiscoverer<span style="color:#f92672">(</span>
         topicsDescriptor<span style="color:#f92672">,</span>
         getRuntimeContext<span style="color:#f92672">().</span><span style="color:#a6e22e">getIndexOfThisSubtask</span><span style="color:#f92672">(),</span>
         getRuntimeContext<span style="color:#f92672">().</span><span style="color:#a6e22e">getNumberOfParallelSubtasks</span><span style="color:#f92672">());</span>
   <span style="color:#66d9ef">this</span><span style="color:#f92672">.</span><span style="color:#a6e22e">partitionDiscoverer</span><span style="color:#f92672">.</span><span style="color:#a6e22e">open</span><span style="color:#f92672">();</span>
   subscribedPartitionsToStartOffsets <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> HashMap<span style="color:#f92672">&lt;&gt;();</span>
   <span style="color:#66d9ef">final</span> List<span style="color:#f92672">&lt;</span>KafkaTopicPartition<span style="color:#f92672">&gt;</span> allPartitions <span style="color:#f92672">=</span> partitionDiscoverer<span style="color:#f92672">.</span><span style="color:#a6e22e">discoverPartitions</span><span style="color:#f92672">();</span>
   <span style="color:#66d9ef">if</span> <span style="color:#f92672">(</span>restoredState <span style="color:#f92672">!=</span> <span style="color:#66d9ef">null</span><span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
      <span style="color:#66d9ef">for</span> <span style="color:#f92672">(</span>KafkaTopicPartition partition <span style="color:#f92672">:</span> allPartitions<span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
         <span style="color:#66d9ef">if</span> <span style="color:#f92672">(!</span>restoredState<span style="color:#f92672">.</span><span style="color:#a6e22e">containsKey</span><span style="color:#f92672">(</span>partition<span style="color:#f92672">))</span> <span style="color:#f92672">{</span>
            restoredState<span style="color:#f92672">.</span><span style="color:#a6e22e">put</span><span style="color:#f92672">(</span>partition<span style="color:#f92672">,</span> KafkaTopicPartitionStateSentinel<span style="color:#f92672">.</span><span style="color:#a6e22e">EARLIEST_OFFSET</span><span style="color:#f92672">);</span>
         <span style="color:#f92672">}</span>
      <span style="color:#f92672">}</span>
      <span style="color:#66d9ef">for</span> <span style="color:#f92672">(</span>Map<span style="color:#f92672">.</span><span style="color:#a6e22e">Entry</span><span style="color:#f92672">&lt;</span>KafkaTopicPartition<span style="color:#f92672">,</span> Long<span style="color:#f92672">&gt;</span> restoredStateEntry <span style="color:#f92672">:</span> restoredState<span style="color:#f92672">.</span><span style="color:#a6e22e">entrySet</span><span style="color:#f92672">())</span> <span style="color:#f92672">{</span>
         <span style="color:#66d9ef">if</span> <span style="color:#f92672">(!</span>restoredFromOldState<span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
           
            <span style="color:#66d9ef">if</span> <span style="color:#f92672">(</span>KafkaTopicPartitionAssigner<span style="color:#f92672">.</span><span style="color:#a6e22e">assign</span><span style="color:#f92672">(</span>
               restoredStateEntry<span style="color:#f92672">.</span><span style="color:#a6e22e">getKey</span><span style="color:#f92672">(),</span> getRuntimeContext<span style="color:#f92672">().</span><span style="color:#a6e22e">getNumberOfParallelSubtasks</span><span style="color:#f92672">())</span>
                  <span style="color:#f92672">==</span> getRuntimeContext<span style="color:#f92672">().</span><span style="color:#a6e22e">getIndexOfThisSubtask</span><span style="color:#f92672">()){</span>
               subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">put</span><span style="color:#f92672">(</span>restoredStateEntry<span style="color:#f92672">.</span><span style="color:#a6e22e">getKey</span><span style="color:#f92672">(),</span> restoredStateEntry<span style="color:#f92672">.</span><span style="color:#a6e22e">getValue</span><span style="color:#f92672">());</span>
            <span style="color:#f92672">}</span>
         <span style="color:#f92672">}</span> <span style="color:#66d9ef">else</span> <span style="color:#f92672">{</span>
           subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">put</span><span style="color:#f92672">(</span>restoredStateEntry<span style="color:#f92672">.</span><span style="color:#a6e22e">getKey</span><span style="color:#f92672">(),</span> restoredStateEntry<span style="color:#f92672">.</span><span style="color:#a6e22e">getValue</span><span style="color:#f92672">());</span>
         <span style="color:#f92672">}</span>
      <span style="color:#f92672">}</span>
      <span style="color:#66d9ef">if</span> <span style="color:#f92672">(</span>filterRestoredPartitionsWithCurrentTopicsDescriptor<span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
         subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">entrySet</span><span style="color:#f92672">().</span><span style="color:#a6e22e">removeIf</span><span style="color:#f92672">(</span>entry <span style="color:#f92672">-&gt;</span> <span style="color:#f92672">{</span>
            <span style="color:#66d9ef">if</span> <span style="color:#f92672">(!</span>topicsDescriptor<span style="color:#f92672">.</span><span style="color:#a6e22e">isMatchingTopic</span><span style="color:#f92672">(</span>entry<span style="color:#f92672">.</span><span style="color:#a6e22e">getKey</span><span style="color:#f92672">().</span><span style="color:#a6e22e">getTopic</span><span style="color:#f92672">()))</span> <span style="color:#f92672">{</span>
               LOG<span style="color:#f92672">.</span><span style="color:#a6e22e">warn</span><span style="color:#f92672">(</span>
                  <span style="color:#e6db74">&#34;{} is removed from subscribed partitions since it is no longer associated with topics descriptor of current execution.&#34;</span><span style="color:#f92672">,</span>
                  entry<span style="color:#f92672">.</span><span style="color:#a6e22e">getKey</span><span style="color:#f92672">());</span>
               <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">true</span><span style="color:#f92672">;</span>
            <span style="color:#f92672">}</span>
            <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">false</span><span style="color:#f92672">;</span>
         <span style="color:#f92672">});</span>
      <span style="color:#f92672">}</span>
      LOG<span style="color:#f92672">.</span><span style="color:#a6e22e">info</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;Consumer subtask {} will start reading {} partitions with offsets in restored state: {}&#34;</span><span style="color:#f92672">,</span>
         getRuntimeContext<span style="color:#f92672">().</span><span style="color:#a6e22e">getIndexOfThisSubtask</span><span style="color:#f92672">(),</span> subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">size</span><span style="color:#f92672">(),</span> subscribedPartitionsToStartOffsets<span style="color:#f92672">);</span>
   <span style="color:#f92672">}</span> <span style="color:#66d9ef">else</span> <span style="color:#f92672">{</span>
    
      <span style="color:#66d9ef">switch</span> <span style="color:#f92672">(</span>startupMode<span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
         <span style="color:#66d9ef">case</span> SPECIFIC_OFFSETS<span style="color:#f92672">:</span>
            <span style="color:#66d9ef">if</span> <span style="color:#f92672">(</span>specificStartupOffsets <span style="color:#f92672">==</span> <span style="color:#66d9ef">null</span><span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
               <span style="color:#66d9ef">throw</span> <span style="color:#66d9ef">new</span> IllegalStateException<span style="color:#f92672">(</span>
                  <span style="color:#e6db74">&#34;Startup mode for the consumer set to &#34;</span> <span style="color:#f92672">+</span> StartupMode<span style="color:#f92672">.</span><span style="color:#a6e22e">SPECIFIC_OFFSETS</span> <span style="color:#f92672">+</span>
                     <span style="color:#e6db74">&#34;, but no specific offsets were specified.&#34;</span><span style="color:#f92672">);</span>
            <span style="color:#f92672">}</span>
            <span style="color:#66d9ef">for</span> <span style="color:#f92672">(</span>KafkaTopicPartition seedPartition <span style="color:#f92672">:</span> allPartitions<span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
               Long specificOffset <span style="color:#f92672">=</span> specificStartupOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">get</span><span style="color:#f92672">(</span>seedPartition<span style="color:#f92672">);</span>
               <span style="color:#66d9ef">if</span> <span style="color:#f92672">(</span>specificOffset <span style="color:#f92672">!=</span> <span style="color:#66d9ef">null</span><span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
                                 subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">put</span><span style="color:#f92672">(</span>seedPartition<span style="color:#f92672">,</span> specificOffset <span style="color:#f92672">-</span> 1<span style="color:#f92672">);</span>
               <span style="color:#f92672">}</span> <span style="color:#66d9ef">else</span> <span style="color:#f92672">{</span>
               subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">put</span><span style="color:#f92672">(</span>seedPartition<span style="color:#f92672">,</span> KafkaTopicPartitionStateSentinel<span style="color:#f92672">.</span><span style="color:#a6e22e">GROUP_OFFSET</span><span style="color:#f92672">);</span>
               <span style="color:#f92672">}</span>
            <span style="color:#f92672">}</span>
            <span style="color:#66d9ef">break</span><span style="color:#f92672">;</span>
         <span style="color:#66d9ef">case</span> TIMESTAMP<span style="color:#f92672">:</span>
            <span style="color:#66d9ef">if</span> <span style="color:#f92672">(</span>startupOffsetsTimestamp <span style="color:#f92672">==</span> <span style="color:#66d9ef">null</span><span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
               <span style="color:#66d9ef">throw</span> <span style="color:#66d9ef">new</span> IllegalStateException<span style="color:#f92672">(</span>
                  <span style="color:#e6db74">&#34;Startup mode for the consumer set to &#34;</span> <span style="color:#f92672">+</span> StartupMode<span style="color:#f92672">.</span><span style="color:#a6e22e">TIMESTAMP</span> <span style="color:#f92672">+</span>
                     <span style="color:#e6db74">&#34;, but no startup timestamp was specified.&#34;</span><span style="color:#f92672">);</span>
            <span style="color:#f92672">}</span>
            <span style="color:#66d9ef">for</span> <span style="color:#f92672">(</span>Map<span style="color:#f92672">.</span><span style="color:#a6e22e">Entry</span><span style="color:#f92672">&lt;</span>KafkaTopicPartition<span style="color:#f92672">,</span> Long<span style="color:#f92672">&gt;</span> partitionToOffset
                  <span style="color:#f92672">:</span> fetchOffsetsWithTimestamp<span style="color:#f92672">(</span>allPartitions<span style="color:#f92672">,</span> startupOffsetsTimestamp<span style="color:#f92672">).</span><span style="color:#a6e22e">entrySet</span><span style="color:#f92672">())</span> <span style="color:#f92672">{</span>
               subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">put</span><span style="color:#f92672">(</span>
                  partitionToOffset<span style="color:#f92672">.</span><span style="color:#a6e22e">getKey</span><span style="color:#f92672">(),</span>
                  <span style="color:#f92672">(</span>partitionToOffset<span style="color:#f92672">.</span><span style="color:#a6e22e">getValue</span><span style="color:#f92672">()</span> <span style="color:#f92672">==</span> <span style="color:#66d9ef">null</span><span style="color:#f92672">)</span>
                      KafkaTopicPartitionStateSentinel<span style="color:#f92672">.</span><span style="color:#a6e22e">LATEST_OFFSET</span>
                        <span style="color:#f92672">:</span> partitionToOffset<span style="color:#f92672">.</span><span style="color:#a6e22e">getValue</span><span style="color:#f92672">()</span> <span style="color:#f92672">-</span> 1<span style="color:#f92672">);</span>
            <span style="color:#f92672">}</span>
            <span style="color:#66d9ef">break</span><span style="color:#f92672">;</span>
         <span style="color:#66d9ef">default</span><span style="color:#f92672">:</span>
            <span style="color:#66d9ef">for</span> <span style="color:#f92672">(</span>KafkaTopicPartition seedPartition <span style="color:#f92672">:</span> allPartitions<span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
               subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">put</span><span style="color:#f92672">(</span>seedPartition<span style="color:#f92672">,</span> startupMode<span style="color:#f92672">.</span><span style="color:#a6e22e">getStateSentinel</span><span style="color:#f92672">());</span>
            <span style="color:#f92672">}</span>
      <span style="color:#f92672">}</span>
      <span style="color:#66d9ef">if</span> <span style="color:#f92672">(!</span>subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">isEmpty</span><span style="color:#f92672">())</span> <span style="color:#f92672">{</span>
         <span style="color:#66d9ef">switch</span> <span style="color:#f92672">(</span>startupMode<span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
            <span style="color:#66d9ef">case</span> EARLIEST<span style="color:#f92672">:</span>
               LOG<span style="color:#f92672">.</span><span style="color:#a6e22e">info</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;Consumer subtask {} will start reading the following {} partitions from the earliest offsets: {}&#34;</span><span style="color:#f92672">,</span>
                  getRuntimeContext<span style="color:#f92672">().</span><span style="color:#a6e22e">getIndexOfThisSubtask</span><span style="color:#f92672">(),</span>
                  subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">size</span><span style="color:#f92672">(),</span>
                  subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">keySet</span><span style="color:#f92672">());</span>
               <span style="color:#66d9ef">break</span><span style="color:#f92672">;</span>
            <span style="color:#66d9ef">case</span> LATEST<span style="color:#f92672">:</span>
               LOG<span style="color:#f92672">.</span><span style="color:#a6e22e">info</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;Consumer subtask {} will start reading the following {} partitions from the latest offsets: {}&#34;</span><span style="color:#f92672">,</span>
                  getRuntimeContext<span style="color:#f92672">().</span><span style="color:#a6e22e">getIndexOfThisSubtask</span><span style="color:#f92672">(),</span>
                  subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">size</span><span style="color:#f92672">(),</span>
                  subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">keySet</span><span style="color:#f92672">());</span>
               <span style="color:#66d9ef">break</span><span style="color:#f92672">;</span>
            <span style="color:#66d9ef">case</span> TIMESTAMP<span style="color:#f92672">:</span>
               LOG<span style="color:#f92672">.</span><span style="color:#a6e22e">info</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;Consumer subtask {} will start reading the following {} partitions from timestamp {}: {}&#34;</span><span style="color:#f92672">,</span>
                  getRuntimeContext<span style="color:#f92672">().</span><span style="color:#a6e22e">getIndexOfThisSubtask</span><span style="color:#f92672">(),</span>
                  subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">size</span><span style="color:#f92672">(),</span>
                  startupOffsetsTimestamp<span style="color:#f92672">,</span>
                  subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">keySet</span><span style="color:#f92672">());</span>
               <span style="color:#66d9ef">break</span><span style="color:#f92672">;</span>
            <span style="color:#66d9ef">case</span> SPECIFIC_OFFSETS<span style="color:#f92672">:</span>
               LOG<span style="color:#f92672">.</span><span style="color:#a6e22e">info</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;Consumer subtask {} will start reading the following {} partitions from the specified startup offsets {}: {}&#34;</span><span style="color:#f92672">,</span>
                  getRuntimeContext<span style="color:#f92672">().</span><span style="color:#a6e22e">getIndexOfThisSubtask</span><span style="color:#f92672">(),</span>
                  subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">size</span><span style="color:#f92672">(),</span>
                  specificStartupOffsets<span style="color:#f92672">,</span>
                  subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">keySet</span><span style="color:#f92672">());</span>
               List<span style="color:#f92672">&lt;</span>KafkaTopicPartition<span style="color:#f92672">&gt;</span> partitionsDefaultedToGroupOffsets <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> ArrayList<span style="color:#f92672">&lt;&gt;(</span>subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">size</span><span style="color:#f92672">());</span>
               <span style="color:#66d9ef">for</span> <span style="color:#f92672">(</span>Map<span style="color:#f92672">.</span><span style="color:#a6e22e">Entry</span><span style="color:#f92672">&lt;</span>KafkaTopicPartition<span style="color:#f92672">,</span> Long<span style="color:#f92672">&gt;</span> subscribedPartition <span style="color:#f92672">:</span> subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">entrySet</span><span style="color:#f92672">())</span> <span style="color:#f92672">{</span>
                  <span style="color:#66d9ef">if</span> <span style="color:#f92672">(</span>subscribedPartition<span style="color:#f92672">.</span><span style="color:#a6e22e">getValue</span><span style="color:#f92672">()</span> <span style="color:#f92672">==</span> KafkaTopicPartitionStateSentinel<span style="color:#f92672">.</span><span style="color:#a6e22e">GROUP_OFFSET</span><span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
                     partitionsDefaultedToGroupOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">add</span><span style="color:#f92672">(</span>subscribedPartition<span style="color:#f92672">.</span><span style="color:#a6e22e">getKey</span><span style="color:#f92672">());</span>
                  <span style="color:#f92672">}</span>
               <span style="color:#f92672">}</span>
               <span style="color:#66d9ef">if</span> <span style="color:#f92672">(</span>partitionsDefaultedToGroupOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">size</span><span style="color:#f92672">()</span> <span style="color:#f92672">&gt;</span> 0<span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
                  LOG<span style="color:#f92672">.</span><span style="color:#a6e22e">warn</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;Consumer subtask {} cannot find offsets for the following {} partitions in the specified startup offsets: {}&#34;</span> <span style="color:#f92672">+</span>
                        <span style="color:#e6db74">&#34;; their startup offsets will be defaulted to their committed group offsets in Kafka.&#34;</span><span style="color:#f92672">,</span>
                     getRuntimeContext<span style="color:#f92672">().</span><span style="color:#a6e22e">getIndexOfThisSubtask</span><span style="color:#f92672">(),</span>
                     partitionsDefaultedToGroupOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">size</span><span style="color:#f92672">(),</span>
                     partitionsDefaultedToGroupOffsets<span style="color:#f92672">);</span>
               <span style="color:#f92672">}</span>
               <span style="color:#66d9ef">break</span><span style="color:#f92672">;</span>
            <span style="color:#66d9ef">case</span> GROUP_OFFSETS<span style="color:#f92672">:</span>
               LOG<span style="color:#f92672">.</span><span style="color:#a6e22e">info</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;Consumer subtask {} will start reading the following {} partitions from the committed group offsets in Kafka: {}&#34;</span><span style="color:#f92672">,</span>
                  getRuntimeContext<span style="color:#f92672">().</span><span style="color:#a6e22e">getIndexOfThisSubtask</span><span style="color:#f92672">(),</span>
                  subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">size</span><span style="color:#f92672">(),</span>
                  subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">keySet</span><span style="color:#f92672">());</span>
         <span style="color:#f92672">}</span>
      <span style="color:#f92672">}</span> <span style="color:#66d9ef">else</span> <span style="color:#f92672">{</span>
         LOG<span style="color:#f92672">.</span><span style="color:#a6e22e">info</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;Consumer subtask {} initially has no partitions to read from.&#34;</span><span style="color:#f92672">,</span>
            getRuntimeContext<span style="color:#f92672">().</span><span style="color:#a6e22e">getIndexOfThisSubtask</span><span style="color:#f92672">());</span>
      <span style="color:#f92672">}</span>
   <span style="color:#f92672">}</span>
<span style="color:#f92672">}</span>
</code></pre></div><p>对 Kafka 中的 Topic 和 Partition 的数据进行读取的核心逻辑都在 run 方法中：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java"><span style="color:#66d9ef">public</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">run</span><span style="color:#f92672">(</span>SourceContext<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;</span> sourceContext<span style="color:#f92672">)</span> <span style="color:#66d9ef">throws</span> Exception <span style="color:#f92672">{</span>
   <span style="color:#66d9ef">if</span> <span style="color:#f92672">(</span>subscribedPartitionsToStartOffsets <span style="color:#f92672">==</span> <span style="color:#66d9ef">null</span><span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
      <span style="color:#66d9ef">throw</span> <span style="color:#66d9ef">new</span> Exception<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;The partitions were not set for the consumer&#34;</span><span style="color:#f92672">);</span>
   <span style="color:#f92672">}</span>
   <span style="color:#66d9ef">this</span><span style="color:#f92672">.</span><span style="color:#a6e22e">successfulCommits</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">this</span><span style="color:#f92672">.</span><span style="color:#a6e22e">getRuntimeContext</span><span style="color:#f92672">().</span><span style="color:#a6e22e">getMetricGroup</span><span style="color:#f92672">().</span><span style="color:#a6e22e">counter</span><span style="color:#f92672">(</span>COMMITS_SUCCEEDED_METRICS_COUNTER<span style="color:#f92672">);</span>
   <span style="color:#66d9ef">this</span><span style="color:#f92672">.</span><span style="color:#a6e22e">failedCommits</span> <span style="color:#f92672">=</span>  <span style="color:#66d9ef">this</span><span style="color:#f92672">.</span><span style="color:#a6e22e">getRuntimeContext</span><span style="color:#f92672">().</span><span style="color:#a6e22e">getMetricGroup</span><span style="color:#f92672">().</span><span style="color:#a6e22e">counter</span><span style="color:#f92672">(</span>COMMITS_FAILED_METRICS_COUNTER<span style="color:#f92672">);</span>
   <span style="color:#66d9ef">final</span> <span style="color:#66d9ef">int</span> subtaskIndex <span style="color:#f92672">=</span> <span style="color:#66d9ef">this</span><span style="color:#f92672">.</span><span style="color:#a6e22e">getRuntimeContext</span><span style="color:#f92672">().</span><span style="color:#a6e22e">getIndexOfThisSubtask</span><span style="color:#f92672">();</span>
   <span style="color:#66d9ef">this</span><span style="color:#f92672">.</span><span style="color:#a6e22e">offsetCommitCallback</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> KafkaCommitCallback<span style="color:#f92672">()</span> <span style="color:#f92672">{</span>
      <span style="color:#a6e22e">@Override</span>
      <span style="color:#66d9ef">public</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">onSuccess</span><span style="color:#f92672">()</span> <span style="color:#f92672">{</span>
         successfulCommits<span style="color:#f92672">.</span><span style="color:#a6e22e">inc</span><span style="color:#f92672">();</span>
      <span style="color:#f92672">}</span>
      <span style="color:#a6e22e">@Override</span>
      <span style="color:#66d9ef">public</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">onException</span><span style="color:#f92672">(</span>Throwable cause<span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
         LOG<span style="color:#f92672">.</span><span style="color:#a6e22e">warn</span><span style="color:#f92672">(</span>String<span style="color:#f92672">.</span><span style="color:#a6e22e">format</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;Consumer subtask %d failed async Kafka commit.&#34;</span><span style="color:#f92672">,</span> subtaskIndex<span style="color:#f92672">),</span> cause<span style="color:#f92672">);</span>
         failedCommits<span style="color:#f92672">.</span><span style="color:#a6e22e">inc</span><span style="color:#f92672">();</span>
      <span style="color:#f92672">}</span>
   <span style="color:#f92672">};</span>

   <span style="color:#66d9ef">if</span> <span style="color:#f92672">(</span>subscribedPartitionsToStartOffsets<span style="color:#f92672">.</span><span style="color:#a6e22e">isEmpty</span><span style="color:#f92672">())</span> <span style="color:#f92672">{</span>
      sourceContext<span style="color:#f92672">.</span><span style="color:#a6e22e">markAsTemporarilyIdle</span><span style="color:#f92672">();</span>
   <span style="color:#f92672">}</span>
   LOG<span style="color:#f92672">.</span><span style="color:#a6e22e">info</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;Consumer subtask {} creating fetcher with offsets {}.&#34;</span><span style="color:#f92672">,</span>
      getRuntimeContext<span style="color:#f92672">().</span><span style="color:#a6e22e">getIndexOfThisSubtask</span><span style="color:#f92672">(),</span> subscribedPartitionsToStartOffsets<span style="color:#f92672">);</span>
  
   <span style="color:#66d9ef">this</span><span style="color:#f92672">.</span><span style="color:#a6e22e">kafkaFetcher</span> <span style="color:#f92672">=</span> createFetcher<span style="color:#f92672">(</span>
         sourceContext<span style="color:#f92672">,</span>
         subscribedPartitionsToStartOffsets<span style="color:#f92672">,</span>
         periodicWatermarkAssigner<span style="color:#f92672">,</span>
         punctuatedWatermarkAssigner<span style="color:#f92672">,</span>
         <span style="color:#f92672">(</span>StreamingRuntimeContext<span style="color:#f92672">)</span> getRuntimeContext<span style="color:#f92672">(),</span>
         offsetCommitMode<span style="color:#f92672">,</span>
         getRuntimeContext<span style="color:#f92672">().</span><span style="color:#a6e22e">getMetricGroup</span><span style="color:#f92672">().</span><span style="color:#a6e22e">addGroup</span><span style="color:#f92672">(</span>KAFKA_CONSUMER_METRICS_GROUP<span style="color:#f92672">),</span>
         useMetrics<span style="color:#f92672">);</span>
   <span style="color:#66d9ef">if</span> <span style="color:#f92672">(!</span>running<span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
      <span style="color:#66d9ef">return</span><span style="color:#f92672">;</span>
   <span style="color:#f92672">}</span>
   <span style="color:#66d9ef">if</span> <span style="color:#f92672">(</span>discoveryIntervalMillis <span style="color:#f92672">==</span> PARTITION_DISCOVERY_DISABLED<span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
      kafkaFetcher<span style="color:#f92672">.</span><span style="color:#a6e22e">runFetchLoop</span><span style="color:#f92672">();</span>
   <span style="color:#f92672">}</span> <span style="color:#66d9ef">else</span> <span style="color:#f92672">{</span>
      runWithPartitionDiscovery<span style="color:#f92672">();</span>
   <span style="color:#f92672">}</span>
<span style="color:#f92672">}</span>
</code></pre></div><h2 id="flink-消费-kafka-数据代码">Flink 消费 Kafka 数据代码</h2>
<p>上面介绍了 Flink 消费 Kafka 的方式，以及消息序列化的方式，同时介绍了分区和 Topic 的动态发现方法，那么回到我们的项目中来，消费 Kafka 数据的完整代码如下：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java"><span style="color:#66d9ef">public</span> <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">KafkaConsumer</span> <span style="color:#f92672">{</span>
    <span style="color:#66d9ef">public</span> <span style="color:#66d9ef">static</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">main</span><span style="color:#f92672">(</span>String<span style="color:#f92672">[]</span> args<span style="color:#f92672">)</span> <span style="color:#66d9ef">throws</span> Exception <span style="color:#f92672">{</span>
        StreamExecutionEnvironment env <span style="color:#f92672">=</span> StreamExecutionEnvironment<span style="color:#f92672">.</span><span style="color:#a6e22e">getExecutionEnvironment</span><span style="color:#f92672">();</span>
        env<span style="color:#f92672">.</span><span style="color:#a6e22e">getCheckpointConfig</span><span style="color:#f92672">().</span><span style="color:#a6e22e">setCheckpointingMode</span><span style="color:#f92672">(</span>CheckpointingMode<span style="color:#f92672">.</span><span style="color:#a6e22e">EXACTLY_ONCE</span><span style="color:#f92672">);</span>
        env<span style="color:#f92672">.</span><span style="color:#a6e22e">enableCheckpointing</span><span style="color:#f92672">(</span>5000<span style="color:#f92672">);</span>
        Properties properties <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> Properties<span style="color:#f92672">();</span>
        properties<span style="color:#f92672">.</span><span style="color:#a6e22e">setProperty</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;bootstrap.servers&#34;</span><span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;127.0.0.1:9092&#34;</span><span style="color:#f92672">);</span>
        <span style="color:#75715e">//设置消费组
</span><span style="color:#75715e"></span>        properties<span style="color:#f92672">.</span><span style="color:#a6e22e">setProperty</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;group.id&#34;</span><span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;group_test&#34;</span><span style="color:#f92672">);</span>
        properties<span style="color:#f92672">.</span><span style="color:#a6e22e">setProperty</span><span style="color:#f92672">(</span>FlinkKafkaConsumerBase<span style="color:#f92672">.</span><span style="color:#a6e22e">KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS</span><span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;10&#34;</span><span style="color:#f92672">);</span>
        FlinkKafkaConsumer<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">&gt;</span> consumer <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> FlinkKafkaConsumer<span style="color:#f92672">&lt;&gt;(</span><span style="color:#e6db74">&#34;test&#34;</span><span style="color:#f92672">,</span> <span style="color:#66d9ef">new</span> SimpleStringSchema<span style="color:#f92672">(),</span> properties<span style="color:#f92672">);</span>
        <span style="color:#75715e">//设置从最早的ffset消费
</span><span style="color:#75715e"></span>        consumer<span style="color:#f92672">.</span><span style="color:#a6e22e">setStartFromEarliest</span><span style="color:#f92672">();</span>
        env<span style="color:#f92672">.</span><span style="color:#a6e22e">addSource</span><span style="color:#f92672">(</span>consumer<span style="color:#f92672">).</span><span style="color:#a6e22e">flatMap</span><span style="color:#f92672">(</span><span style="color:#66d9ef">new</span> FlatMapFunction<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">,</span> String<span style="color:#f92672">&gt;()</span> <span style="color:#f92672">{</span>
            <span style="color:#a6e22e">@Override</span>
            <span style="color:#66d9ef">public</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">flatMap</span><span style="color:#f92672">(</span>String value<span style="color:#f92672">,</span> Collector<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">&gt;</span> out<span style="color:#f92672">)</span> <span style="color:#66d9ef">throws</span> Exception <span style="color:#f92672">{</span>
                System<span style="color:#f92672">.</span><span style="color:#a6e22e">out</span><span style="color:#f92672">.</span><span style="color:#a6e22e">println</span><span style="color:#f92672">(</span>value<span style="color:#f92672">);</span>
            <span style="color:#f92672">}</span>
        <span style="color:#f92672">});</span>
        env<span style="color:#f92672">.</span><span style="color:#a6e22e">execute</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;start consumer...&#34;</span><span style="color:#f92672">);</span>
    <span style="color:#f92672">}</span>
<span style="color:#f92672">}</span>
</code></pre></div><p>我们可以直接右键运行代码，在控制台中可以看到数据的正常打印，如下图所示：</p>
<p><figure><img src="/images/ring.svg" data-src="/images/%E9%80%9A%E8%BF%87%E4%BB%A3%E7%A0%81.png" data-sizes="auto" alt="通过代码" title="通过代码" class="lazyload"><figcaption class="image-caption">通过代码</figcaption></figure></p>
<p>通过代码可知，我们之前发往 Kafka 的消息被完整地打印出来了。</p>
<h2 id="总结">总结</h2>
<p>这一课时介绍了 Flink 消费 Kafka 的方式，比如从常用的指定单个或者多个 Topic、消息的序列化、分区的动态发现等，还从源码上介绍了 Flink 消费 Kafka 的原理。通过本课时的学习，相信你可以对 Flink 消费 Kafka 有一个较为全面地了解，根据业务场景可以正确选择消费的方式和配置。</p>
<p><a href="https://github.com/wangzhiwubigdata/quickstart">点击这里下载本课程源码</a>。</p>

    </div>

    <div class="post-copyright">
             
            <p class="copyright-item">
                <span>Author:</span>
                <span>追寻原风景 </span>
                </p>
            
           
             
            <p class="copyright-item">
                    <span>Link:</span>
                    <a href=https://xiaohao890809.github.io/2020/2020-07-20-the-lessons-of-flink-25/>https://xiaohao890809.github.io/2020/2020-07-20-the-lessons-of-flink-25/</span>
            </p>
            
             
            <p class="copyright-item lincese">
                本文采用<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可
            </p>
            
    </div>

  
    <div class="post-tags">
        
            <section>
            <i class="iconfont icon-tag"></i>Tag(s): 
            
            <span class="tag"><a href="https://xiaohao890809.github.io/tags/42%E8%AE%B2%E8%BD%BB%E6%9D%BE%E9%80%9A%E5%85%B3flink/">
                    #42讲轻松通关Flink</a></span>
            
            </section>
        
        <section>
                <a href="javascript:window.history.back();">back</a></span> · 
                <span><a href="https://xiaohao890809.github.io">home</a></span>
        </section>
    </div>

    <div class="post-nav">
        
        <a href="https://xiaohao890809.github.io/2020/2020-07-20-the-lessons-of-flink-24/" class="prev" rel="prev" title="第23讲：Mock Kafka 消息并发送"><i class="iconfont icon-left"></i>&nbsp;第23讲：Mock Kafka 消息并发送</a>
         
        
        <a href="https://xiaohao890809.github.io/2020/2020-07-20-the-lessons-of-flink-26/" class="next" rel="next" title="第25讲：Flink 中 watermark 的定义和使用">第25讲：Flink 中 watermark 的定义和使用&nbsp;<i class="iconfont icon-right"></i></a>
        
    </div>

    <div class="post-comment">
        
        
    </div>

</article>
          </div>
		   </main>
      <footer class="footer">
    <div class="copyright">
        &copy;
        
        <span itemprop="copyrightYear">2015 - 2020</span>
        
        <span class="with-love">
    	 <i class="iconfont icon-love"></i> 
         </span>
         
            <span class="author" itemprop="copyrightHolder"><a href="https://xiaohao890809.github.io">追寻原风景</a> | </span> 
         

         
		  <span>Powered by <a href="https://gohugo.io/" target="_blank" rel="external nofollow">Hugo</a> & <a href="https://github.com/liuzc/leaveit" target="_blank" rel="external nofollow">LeaveIt</a></span> 
    </div>
</footer>













    
     <link href="//lib.baomitu.com/lightgallery/1.6.11/css/lightgallery.min.css" rel="stylesheet">  
      
     <script src="/js/vendor_gallery.min.js" async="" ></script>
    
  



     </div>
  </body>
</html>
